---
name: audit
description: Full smart contract security audit with Phase 1 recon and Phase 2 deep analysis
---

# /vigilo:audit - Full Security Audit

Execute a comprehensive security audit on smart contracts using a **protocol-first approach**.

## Core Philosophy

> **"공격자처럼 생각하라"** - Think like an attacker
> - 돈은 어디에 있는가? (Where's the money?)
> - 어떻게 훔칠 수 있는가? (How can it be stolen?)
> - 어떤 가정이 깨지면 돈을 잃는가? (What assumptions, if broken, cause fund loss?)


## Your Task

Perform a complete security audit in multiple phases:

### Phase 0: Check Existing Recon (Pre-flight)

Before starting Phase 1, check if previous reconnaissance data exists:

1. **Check for existing recon files**
   ```
   Glob(".vigilo/recon/doc-findings.md")
   Glob(".vigilo/recon/code-findings.md")
   ```

2. **If BOTH files exist and are non-empty:**
   - Read and validate the files contain valid findings (check for expected sections like "## Summary", "## Contracts", etc.)
   - Display summary to user: "Found existing recon data. Reusing for attack scenario generation."
   - **Skip Phase 1 entirely** and proceed to Phase 1.5 (Agent Selection)

3. **If files are missing, empty, or invalid:**
   - Proceed with normal Phase 1 execution

### Phase 1: Reconnaissance (Quick Scan)

> **Note**: Skip this phase if Phase 0 found valid existing recon data.

First, gather intelligence about the codebase:

1. **Scope Definition** (CRITICAL - Must respect scope boundaries)

   Determine audit scope in this order:

   **Step 1: Check for existing scope**
   - If `$ARGUMENTS` provided: Use specified files directly
   - If `scope.txt` exists: Read and use those files

   **Step 2: If no scope defined, prompt user**

   If neither `$ARGUMENTS` nor `scope.txt` exists, you MUST ask the user using AskUserQuestion:

   ```json
   AskUserQuestion({
     "questions": [{
       "question": "No scope.txt found. How would you like to define the audit scope?",
       "header": "Scope",
       "options": [
         { "label": "Auto-detect", "description": "Scan project for smart contract files (.sol, .rs, .cairo, .move)" },
         { "label": "Enter manually", "description": "I will paste the file paths or contract names" },
         { "label": "Entire project", "description": "Audit all smart contract files in the project" }
       ],
       "multiSelect": false
     }]
   })
   ```

   **Based on user response:**
   - **Auto-detect**: Scan for contract files using Glob, show list to user, and ask for confirmation
   - **Enter manually**: Ask user to paste file paths (one per line), then confirm
   - **Entire project**: Find all .sol/.rs/.cairo/.move files automatically

   **After scope is confirmed, save to scope.txt:**
   ```
   Write("scope.txt", "<confirmed_files_one_per_line>")
   ```

   **scope.txt format:**
   ```
   # Lines starting with # are comments
   # Generated by vigilo audit
   src/Pool.sol
   src/Token.sol
   src/libraries/Math.sol
   ```

   **IMPORTANT**: Only analyze files within the confirmed scope.

2. **Documentation Analysis**
   Analyze project documentation to extract:
   - Protocol invariants and trust assumptions
   - Business logic and mechanisms
   - Security considerations from documentation

   The `doc-reader` agent will be automatically delegated based on this analysis task.
   Output: `.vigilo/recon/doc-findings.md`

3. **Code Structure Analysis**
   Map the contract architecture to identify:
   - Contract architecture and inheritance
   - Entry points (external/public functions)
   - **자산 저장소 및 흐름 경로** (Asset storage and flow paths)
   - **프로토콜 유형 자동 판단** (Protocol type auto-detection)
   - Attack surface markers

   The `code-analyzer` agent will be automatically delegated based on this analysis task.
   Output: `.vigilo/recon/code-findings.md`

Wait for Phase 1 reconnaissance to complete before proceeding.

### Phase 1.5: Agent Auto-Selection (Critical Step)

After Phase 0/1 completes, **automatically select the TOP 3 most relevant auditors** based on **BOTH** protocol type AND attack surface markers from recon.

**Input Sources**:
- `.vigilo/recon/doc-findings.md` - Protocol invariants, trust assumptions, security considerations
- `.vigilo/recon/code-findings.md` - Code architecture, asset flows, protocol type, **attack surface markers**

1. **Read Recon Results**
   ```
   Read(".vigilo/recon/doc-findings.md")
   Read(".vigilo/recon/code-findings.md")
   ```

2. **Extract Selection Criteria**

   **2.1 Protocol Type** (from code-findings.md):
   - Look for "프로토콜 유형 판단" or "Protocol Type" section
   - This provides base recommendation

   **2.2 Attack Surface Markers** (from code-findings.md):
   - Look for "Attack Surface" or "공격 표면" section
   - Extract detected patterns that override/adjust base selection

   | Attack Surface Marker | Indicator Auditor | Weight |
   |-----------------------|-------------------|--------|
   | External calls (`.call`, `transfer`, `safeTransfer`) | `state-interaction-auditor` | +2 |
   | Callbacks (`onERC721Received`, `tokensReceived`, hooks) | `state-interaction-auditor` | +2 |
   | Oracle integration (`getPrice`, `latestAnswer`, TWAP) | `economic-attack-auditor` | +2 |
   | Flash loan support (`flashLoan`, `onFlashLoan`) | `economic-attack-auditor` | +2 |
   | Complex math (`mulDiv`, `sqrt`, decimals conversion) | `logic-error-auditor` | +2 |
   | Role-based access (`onlyOwner`, `hasRole`, access mapping) | `access-control-auditor` | +2 |
   | Upgradeable patterns (proxy, `delegatecall`) | `state-interaction-auditor` | +1 |
   | Multi-contract interaction (cross-contract calls) | `state-interaction-auditor` | +1 |
   | Price calculations (reserves, ratios) | `economic-attack-auditor` | +1 |
   | Input validation gaps (missing checks) | `logic-error-auditor` | +1 |

   **2.3 Documentation Signals** (from doc-findings.md "Auditor Indicators" section):
   - Read the "Auditor Indicators (Phase 1.5 Input)" table
   - Extract weights directly from the doc-reader output

   | Signal Category | Auditor Indicator | Weight |
   |-----------------|-------------------|--------|
   | Oracle/price feed dependencies | economic-attack | +2 |
   | Flash loan integration | economic-attack | +2 |
   | Liquidation mechanisms | economic-attack | +1 |
   | Callback/hook mentions | state-interaction | +2 |
   | External integrations | state-interaction | +1 |
   | Complex math/calculations | logic-error | +2 |
   | Balance invariants | logic-error | +1 |
   | Role-based access | access-control | +2 |
   | Admin capabilities | access-control | +1 |

3. **Agent Selection Algorithm**

   **Step 1**: Start with protocol-type base scores:

   | Protocol Type | state-interaction | economic-attack | logic-error | access-control |
   |---------------|-------------------|-----------------|-------------|----------------|
   | AMM/DEX | 2 | 3 | 2 | 0 |
   | Lending | 1 | 3 | 3 | 2 |
   | Vault | 3 | 2 | 2 | 0 |
   | Governance | 2 | 0 | 2 | 3 |
   | NFT | 2 | 0 | 2 | 3 |
   | Bridge | 3 | 1 | 2 | 3 |
   | Unknown | 2 | 1 | 2 | 2 |

   **Step 2**: Add weights from BOTH recon outputs:
   - From `code-findings.md` → "Auditor Indicators" table (code patterns)
   - From `doc-findings.md` → "Auditor Indicators" table (documentation signals)

   **Step 3**: Select TOP 3 auditors by final score

   **Example**:
   ```
   Protocol: Vault (base: state=3, economic=2, logic=2, access=0)

   Code markers (from code-findings.md):
     - External calls (+2 state)
     - Oracle integration (+2 economic)

   Doc signals (from doc-findings.md):
     - Balance invariants mentioned (+1 logic)
     - Admin capabilities documented (+1 access)

   Final scores:
     state = 3 + 2 = 5
     economic = 2 + 2 = 4
     logic = 2 + 1 = 3
     access = 0 + 1 = 1

   Selected: state-interaction (5), economic-attack (4), logic-error (3)
   ```

4. **Available Auditors (4개)**

   | Auditor | Coverage |
   |---------|----------|
   | `state-interaction-auditor` | Reentrancy, external calls, cross-contract state, callbacks |
   | `economic-attack-auditor` | Flash loans, oracle manipulation, price manipulation, MEV |
   | `logic-error-auditor` | Business logic, calculation errors, input validation |
   | `access-control-auditor` | Privilege escalation, authentication bypass, role manipulation |

5. **Display Selection Rationale and Confirm with User**

   Before launching agents, display:
   - Detected protocol type
   - **Detected attack surface markers** (key patterns found)
   - Final scores per auditor
   - Why these 3 agents were selected

   ```json
   AskUserQuestion({
     "questions": [{
       "question": "Agent selection: {agent1} (score:{s1}), {agent2} (score:{s2}), {agent3} (score:{s3}). Based on {protocol_type} + attack surface markers: {markers}. Proceed?",
       "header": "Agents",
       "options": [
         { "label": "Proceed", "description": "Run selected 3 auditors" },
         { "label": "Swap one agent", "description": "I want to replace one of the selected agents" },
         { "label": "Custom selection", "description": "Let me choose all 3 agents manually" }
       ],
       "multiSelect": false
     }]
   })
   ```

   **If user wants to swap or customize:**
   - Show all 4 available auditors with scores and descriptions
   - Let user select exactly 3 agents
   - Confirm final selection before proceeding

### Phase 2: Deep Security Analysis (3 Agents in Parallel)

Launch **exactly 3 selected auditors** for deep security analysis.

**Delegation Method**: Describe each auditor's task in natural language. Claude will automatically delegate to the appropriate agent based on the agent's description field.

**Example delegation for selected auditors:**

> "Analyze the contracts for state interaction vulnerabilities including reentrancy, external call risks, cross-contract state dependencies, and callback attack vectors. Read recon data from `.vigilo/recon/` and generate attack scenarios."

> "Analyze the contracts for economic attack vectors including flash loan attacks, oracle manipulation, price manipulation, and MEV vulnerabilities. Read recon data from `.vigilo/recon/` and generate attack scenarios."

> "Analyze the contracts for logic errors including business logic flaws, calculation errors, rounding issues, and input validation problems. Read recon data from `.vigilo/recon/` and generate attack scenarios."

**IMPORTANT**:
- Always run exactly 3 auditors (not more, not less)
- Each auditor will be automatically delegated based on task description
- Each auditor will:
  1. Read Phase 1 recon data
  2. Apply 공격자 마인드셋 (Attacker Mindset)
  3. Use analysis framework skills (invariant-analysis, asset-flow-analysis, state-sync-analysis)
  4. Generate **공격 시나리오** (Attack Scenarios) - NOT PoC code
  5. Write findings to `.vigilo/findings/{severity}/{auditor-type}/`

### Phase 2 Complete: Attack Scenario Review & Selection (HITL)

After all 3 auditors complete, **summarize the generated attack scenarios for user review**.

**Step 1: Collect All Findings**
```
Glob(".vigilo/findings/**/*.md")
```

Read each finding and extract:
- Finding ID (H-01, M-01, etc.)
- Title
- Auditor type (state-interaction, economic-attack, logic-error)
- Severity
- Brief attack scenario summary (1-2 sentences)

**Step 2: Present Attack Scenarios Summary**

Display a table to the user:

```markdown
## Phase 2 Complete: Attack Scenarios Generated

| ID | Severity | Auditor | Title | Attack Summary |
|----|----------|---------|-------|----------------|
| H-01 | High | state-interaction | Reentrancy in withdraw() | Attacker can re-enter during ETH transfer |
| H-02 | High | economic-attack | Oracle manipulation | Flash loan to manipulate TWAP price |
| M-01 | Medium | logic-error | Rounding error in fee calculation | Accumulate rounding gains over multiple txs |
| M-02 | Medium | state-interaction | Read-only reentrancy | External protocol reads stale totalAssets |
| L-01 | Low | logic-error | Missing zero-check | Edge case with zero amount |
```

**Step 3: Ask User to Select Scenarios for PoC Validation**

```json
AskUserQuestion({
  "questions": [{
    "question": "Which attack scenarios should we validate with PoC code?",
    "header": "PoC Selection",
    "options": [
      { "label": "All High/Critical", "description": "Generate PoC for all High and Critical findings only" },
      { "label": "All High + Medium", "description": "Generate PoC for High and Medium findings" },
      { "label": "All findings", "description": "Generate PoC for every finding (may take longer)" },
      { "label": "Let me choose", "description": "I'll specify which finding IDs to validate" }
    ],
    "multiSelect": false
  }]
})
```

**If user chooses "Let me choose":**
- Ask for specific finding IDs (comma-separated, e.g., "H-01, H-02, M-01")
- Validate only the selected findings

**Step 4: Confirm Selection Before Proceeding**

Display selected findings and ask for final confirmation before generating PoC code.

---

### Phase 2.5: PoC Generation & Validation

**Only validate the user-selected attack scenarios** from the previous step.

**Use the `poc-generation` skill for this phase.** The skill provides:
- PoC templates by bug class
- Error patterns and fixes
- Validation workflow

**Workflow (Sequential Per Finding):**

**IMPORTANT**: Process ONE finding at a time. Complete full validation cycle before moving to next.

```
For each selected finding:
    1. Generate PoC (one file)
    2. Run test (single file only)
    3. If fail → retry up to 3 times
    4. If still fail → ask user (HITL)
    5. Record result (VALIDATED/INVALIDATED/NEEDS_REVIEW)
    6. Move to next finding
```

**For Each Selected Finding (Sequential):**

1. **Read Attack Scenario**
   - Read `.vigilo/findings/{severity}/{finding-id}.md`
   - Extract: preconditions, attack steps, expected impact

2. **Generate PoC Code**
   - Use `poc-generation` skill templates
   - Write ONE test file: `test/poc/{finding-id}-{bug-class}.t.sol`

3. **Run Single Test with Bash** (CRITICAL - ONE AT A TIME!)

   **✅ CORRECT - Single file per Bash call:**
   ```
   Bash("forge test --match-path 'test/poc/H-01-*.t.sol' -vvv")
   ```

   **❌ WRONG - Never batch multiple PoCs:**
   ```
   # DO NOT DO THIS
   Bash("forge test --match-path 'test/poc/*.t.sol' -vvv")
   ```

   **❌ WRONG - Never run multiple tests in parallel:**
   ```
   # DO NOT DO THIS
   Bash("forge test --match-test 'test_Exploit' -vvv")
   ```

   **Why One at a Time?**
   - Isolates failures for easier debugging
   - Enables per-finding HITL decisions
   - Prevents cascading test failures
   - Clearer validation status per finding

4. **Handle Result**

   - **PASS** → Mark as VALIDATED, move to next finding
   - **FAIL** → Apply fixes (max 3 retries):
     - Compile Errors: Fix imports, types, signatures
     - Runtime Errors: Fix funding, approvals, state setup
     - Assertion Failures: Adjust attack parameters

5. **After 3 Failures - Ask User (HITL)**:

   ```json
   AskUserQuestion({
     "questions": [{
       "question": "PoC for {finding_id} failed 3 times. How should we proceed?",
       "header": "PoC Fail",
       "options": [
         { "label": "Re-analyze", "description": "Trigger re-analysis to modify attack scenario and retry" },
         { "label": "Mark as NEEDS_REVIEW", "description": "Skip further attempts, flag for manual review" },
         { "label": "Invalidate", "description": "Mark as false positive (INVALIDATED) and move on" }
       ],
       "multiSelect": false
     }]
   })
   ```

   **If user chooses Re-analyze**, trigger re-analysis:
   ```markdown
   ## Re-Analysis Trigger

   The original attack scenario may have incorrect assumptions.

   1. Read the original finding file
   2. Analyze WHY the PoC failed:
      - Wrong function signature?
      - Missing preconditions?
      - Incorrect state assumptions?
      - Invalid attack sequence?

   3. Generate a MODIFIED attack scenario:
      - Adjust the attack sequence
      - Add missing setup steps
      - Correct state assumptions

   4. Regenerate PoC from modified scenario
   5. Retry validation (max 2 additional attempts)
   ```

   **Step 3**: If re-analysis also fails, mark as NEEDS_REVIEW

5. **Record Results**

   Update each finding with validation status:
   - **VALIDATED**: PoC test passes, exploit confirmed
   - **INVALIDATED**: PoC fails after re-analysis, likely false positive
   - **NEEDS_REVIEW**: Complex scenario requiring manual review

6. **Summary Table**

   After all tests complete, display summary:
   ```
   | Finding | Test File | Status | Re-Analysis | Notes |
   |---------|-----------|--------|-------------|-------|
   | H-01 | test/poc/H-01-state-interaction.t.sol | VALIDATED | No | Read-only reentrancy confirmed |
   | M-01 | test/poc/M-01-economic-attack.t.sol | VALIDATED | Yes | Modified flash loan sequence |
   | M-02 | test/poc/M-02-logic-error.t.sol | INVALIDATED | Yes | Rounding error too small to exploit |
   ```

### Phase 3: Report Generation

After Phase 2.5 PoC validation completes:

1. **Collect All Findings**
   Read all findings from `.vigilo/findings/` directory

2. **Filter by Validation Status**
   - Include: VALIDATED findings
   - Separate section: NEEDS_REVIEW findings (for manual inspection)
   - Exclude: INVALIDATED findings (false positives)

3. **Generate Integrated Report**
   Write final report to `.vigilo/reports/{YYYY_MM_DD_HHMM}_audit.md`

   Report format:
   ```markdown
   # Security Audit Report

   **Project**: {project name}
   **Date**: {date}
   **Protocol Type**: {detected type}
   **Auditors Used**: {3 selected auditors}

   ## Executive Summary
   - Total Findings: X
   - Validated: Y
   - Needs Review: Z

   ## High Severity
   ### [H-01] {Title}
   - **Auditor**: {auditor type}
   - **Validation**: VALIDATED
   - **PoC**: test/poc/H-01-xxx.t.sol
   - **Description**: ...
   - **Impact**: ... (NO DOLLAR AMOUNTS)
   - **Recommendation**: ...

   ## Medium Severity
   ...

   ## Needs Manual Review
   ...
   ```

## Severity Classification (Code4rena Standard)

| Severity | Criteria | Impact Assessment |
|----------|----------|-------------------|
| **Critical** | Direct fund drain, protocol insolvency | Total loss of deposited funds |
| **High** | Significant fund loss, privilege escalation | Major loss or unauthorized control |
| **Medium** | Limited fund loss, conditional exploits | Partial loss under specific conditions |
| **Low** | Best practice violations, edge cases | Minimal impact, unlikely exploitation |

**CRITICAL**: Impact는 정성적으로만 평가. 절대 수익 금액을 숫자로 계산하지 마세요.

## Guidelines

1. **Sequential Phases**: Phase 0 → Phase 1 (if needed) → Phase 1.5 → Phase 2 → Phase 2 Complete (HITL) → Phase 2.5 → Phase 3
2. **Recon Reuse**: Skip Phase 1 if valid recon data exists in `.vigilo/recon/`
3. **Auto Selection**: Phase 1.5 automatically selects 3 agents based on protocol type
4. **Parallel Auditors**: Run exactly 3 agents simultaneously in Phase 2
5. **Attack Scenarios First**: Phase 2 auditors generate attack scenarios, NOT PoC code
6. **User Selection (HITL)**: After Phase 2, user reviews and selects which scenarios to validate
7. **PoC Generation**: Main agent generates PoC code ONLY for user-selected scenarios
8. **Re-Analysis on Failure**: If PoC fails, modify attack scenario and retry
9. **Protocol-First**: Understand protocol mechanics before pattern matching
10. **attacker mindset**: All analysis starts with "Where's the money?" mindset
11. **No Numeric Profits**: Never calculate dollar amounts - qualitative impact only
12. **Code4rena Format**: All findings follow Code4rena report standards
13. **Evidence-Based**: Only VALIDATED findings go in final report

## Workflow Diagram

```
Phase 0: 기존 정찰 확인
    │
    ├─[존재]→ Phase 1.5로 이동
    │
    └─[없음]→ Phase 1: 정찰
                ├── doc-reader (문서 분석)
                └── code-analyzer (코드 매핑)
                        │
                        ▼
              Phase 1.5: 에이전트 자동 선택 (HITL)
                ├── 프로토콜 유형 판단
                ├── 3개 에이전트 선택
                └── 사용자 확인/재정의
                        │
                        ▼
              Phase 2: 심층 분석 (병렬)
                ├── Agent 1 ─┐
                ├── Agent 2 ─┼── 공격 시나리오 생성
                └── Agent 3 ─┘
                        │
                        ▼
              Phase 2 Complete: 시나리오 리뷰 (HITL)
                ├── 생성된 시나리오 요약 표시
                ├── 사용자가 검증할 시나리오 선택
                └── 선택 확인
                        │
                        ▼
              Phase 2.5: PoC 검증 (선택된 것만)
                ├── PoC 생성
                ├── 테스트 실행
                ├── 실패 시 사용자에게 질문 (HITL) ─┐
                │       ◄────────────────────────────┘
                └── 결과 기록
                        │
                        ▼
              Phase 3: 리포트 생성
                └── VALIDATED만 포함
```
